{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import yaml\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dataset import Dataset\n",
    "from tools.test import test\n",
    "from tools.train import train\n",
    "from check_cuda import check_cuda\n",
    "from models.ResnetFFN import ResnetFFN\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "csv_file_path = \"./data/CodingChallenge_v2/car_imgs_4000.csv\"\n",
    "images_dir = \"./data/CodingChallenge_v2/imgs\"\n",
    "\n",
    "# Initialize list to hold training data\n",
    "images = []\n",
    "scores_hood = []\n",
    "scores_backdoor_left = []\n",
    "\n",
    "IMG_H = 224\n",
    "IMG_W = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set predetermined mean and std values\n",
    "mean_images = np.array([122.09624237, 123.38567456, 120.75862292]) / 255.0\n",
    "std_images = np.array([61.13438223, 62.09970917, 65.60647365]) / 255.0\n",
    "\n",
    "# Resize images, convert to torch.Tensor and normalize the dataset regarding predetermined mean and std values\n",
    "transform_norm = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(\n",
    "            (IMG_H, IMG_W)\n",
    "        ),  # Resize images to (IMG_H x IMG_W)\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean_images, std_images),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "with open(csv_file_path, mode=\"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "\n",
    "    # Skip the header\n",
    "    next(csv_reader)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        filename, score_hood, score_backdoor_left = row\n",
    "        # print(f\"Filename: {filename}, Score Hood: {score_hood}, Score Backdoor Left: {score_backdoor_left}\")\n",
    "        image_path = os.path.join(images_dir, filename)\n",
    "\n",
    "        # Check if the image file exists\n",
    "        if os.path.exists(image_path):\n",
    "\n",
    "            # Append image and perspective scores to the corresponding lists\n",
    "            with Image.open(image_path) as img:\n",
    "                images.append(np.array(transform_norm(img), dtype=np.float32))\n",
    "\n",
    "            scores_hood.append(np.array(float(score_hood), dtype=np.float32))\n",
    "            scores_backdoor_left.append(\n",
    "                np.array(float(score_backdoor_left), dtype=np.float32)\n",
    "            )\n",
    "\n",
    "# Check if some scores are NaN\n",
    "for i in range(len(images)):\n",
    "    if np.isnan(scores_hood[i]) or np.isnan(scores_backdoor_left[i]):\n",
    "        print(f\"Found NaN scores at index {i}\")\n",
    "        break\n",
    "\n",
    "images = np.array(images)  # Shape: (4000, 3, IMG_H, IMG_W)\n",
    "scores_hood = np.array(scores_hood).reshape(-1, 1)  # Shape: (4000, 1)\n",
    "scores_backdoor_left = np.array(scores_backdoor_left).reshape(-1, 1)  # Shape: (4000, 1)\n",
    "\n",
    "# Test size of variables\n",
    "print(f\"Images Shape: {images.shape}\")\n",
    "print(f\"Scores Hood Shape: {scores_hood.shape}\")\n",
    "print(f\"Scores Backdoor Left Shape: {scores_backdoor_left.shape}\")\n",
    "print(\"\")\n",
    "print(\n",
    "    \"Mean of Image Pixels: \",\n",
    "    np.mean(images, axis=(0, 2, 3)),\n",
    "    \"   ->   [values should be near 0!]\",\n",
    ")\n",
    "print(\n",
    "    \"Standard Deviation of Image Pixels: \",\n",
    "    np.std(images, axis=(0, 2, 3)),\n",
    "    \"   ->   [values should be near 1!]\",\n",
    ")\n",
    "# print(f\"Mean of images: {mean_images}\")\n",
    "# print(f\"Std of images: {std_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the pixel values\n",
    "plt.hist(images.ravel(), bins=50, density=True)\n",
    "plt.xlabel(\"pixel values\")\n",
    "plt.ylabel(\"relative frequency\")\n",
    "plt.title(\"distribution of pixels\")\n",
    "\n",
    "print(\n",
    "    \"\"\"\\nIMPORTANT: Our dataset includes a lot of white pixels, which is due to the fact\n",
    "            that the images are synthetically generated and have a lot of white backgrounds!\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the perspective scores characteristics\n",
    "\n",
    "scores_hood = np.array(scores_hood)\n",
    "scores_backdoor_left = np.array(scores_backdoor_left)\n",
    "\n",
    "print(\n",
    "    f\"Score hood: min={scores_hood.min()}, max={scores_hood.max()}, \\\n",
    "mean={scores_hood.mean()}, std={scores_hood.std()}, num_zeros={np.count_nonzero(scores_hood==0)}, \\\n",
    "mean_non_zero={np.mean(scores_hood[scores_hood!=0])}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Score backdoor left: min={scores_backdoor_left.min()}, \\\n",
    "max={scores_backdoor_left.max()}, mean={scores_backdoor_left.mean()}, \\\n",
    "std={scores_backdoor_left.std()}, num_zeros={np.count_nonzero(scores_backdoor_left==0)}, \\\n",
    "mean_non_zero={np.mean(scores_backdoor_left[scores_backdoor_left!=0])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to tensors and prepare input data\n",
    "X = torch.from_numpy(images)  # Size: ([4000, 506, 674, 3])\n",
    "\n",
    "# Concatenate the two scores into a single tensor as the model's output data\n",
    "y = torch.from_numpy(\n",
    "    np.concatenate((scores_hood, scores_backdoor_left), axis=1)\n",
    ")  # Size: [(4000, 2)]\n",
    "\n",
    "print(\"X size:\", X.size(), \"X type:\", type(X), \"X.dtype:\", X.dtype)\n",
    "print(\"y size:\", y.size(), \"y type:\", type(y), \"y.dtype:\", y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cuda availability\n",
    "check_cuda()\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train, test and validation ratios\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.1\n",
    "val_ratio = 0.1\n",
    "\n",
    "# Split the data / Shuffle it and maintain class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=(1 - train_ratio), random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Further split train_data into test and validation sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    test_size=test_ratio / (test_ratio + val_ratio),\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "print(\"X_train size: \", X_train.size())\n",
    "print(\"X_test size: \", X_test.size())\n",
    "print(\"X_val size: \", X_val.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Push torch.Tensors to CPU\n",
    "# X_train, y_train = X_train.to('cpu', dtype=torch.float32), y_train.to('cpu', dtype=torch.float32)\n",
    "# X_test, y_test = X_test.to('cpu', dtype=torch.float32), y_test.to('cpu', dtype=torch.float32)\n",
    "# X_val, y_val = X_val.to('cpu', dtype=torch.float32), y_val.to('cpu', dtype=torch.float32)\n",
    "\n",
    "# Create a custom dataset and push tensors to CPU\n",
    "train_dataset = Dataset(X_train, y_train, \"cpu\")\n",
    "test_dataset = Dataset(X_test, y_test, \"cpu\")\n",
    "val_dataset = Dataset(X_val, y_val, \"cpu\")\n",
    "\n",
    "del X, y, X_train, y_train, X_test, y_test, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how much memory (VRAM) is allocated to GPU\n",
    "gpu_memory_allocated = torch.cuda.memory_allocated(device)\n",
    "\n",
    "# Convert memory from bytes to GB\n",
    "gpu_memory_allocated_gb = gpu_memory_allocated / 1024**3\n",
    "\n",
    "# Print the memory allocated to the GPU\n",
    "print(\"GPU Memory Allocated:\", gpu_memory_allocated_gb, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config\n",
    "\n",
    "with open(os.getenv(\"CONFIG_DIR\"), \"r\") as config_file:\n",
    "    config_model = yaml.safe_load(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN-FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize W&B for RNN-Classifier\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=config_model[\"Project\"][\"project_name\"],\n",
    "    # track hyperparameters and run metadata\n",
    "    config=dict(\n",
    "        device=device,\n",
    "        project_name=config_model[\"Project\"][\"project_name\"],\n",
    "        model_name=config_model[\"Model\"][\"model_name\"],\n",
    "        num_outputs=config_model[\"Model\"][\"num_outputs\"],\n",
    "        batch_first=config_model[\"Model\"][\"batch_first\"],\n",
    "        conv_channel=config_model[\"Model\"][\"conv_channel\"],\n",
    "        fc_hidden_dims=config_model[\"Model\"][\"fc_hidden_dims\"],\n",
    "        batch_size=config_model[\"Dataloader\"][\"batch_size\"],\n",
    "        shuffle=config_model[\"Dataloader\"][\"shuffle\"],\n",
    "        num_workers=config_model[\"Dataloader\"][\"num_workers\"],\n",
    "        pin_memory=config_model[\"Dataloader\"][\"pin_memory\"],\n",
    "        drop_last=config_model[\"Dataloader\"][\"drop_last\"],\n",
    "        optimizer=config_model[\"Optimizer\"][\"optimizer\"],\n",
    "        backbone_lr=float(config_model[\"Optimizer\"][\"backbone_lr\"]),\n",
    "        other_lr=float(config_model[\"Optimizer\"][\"other_lr\"]),\n",
    "        beta1=config_model[\"Optimizer\"][\"beta1\"],\n",
    "        beta2=config_model[\"Optimizer\"][\"beta2\"],\n",
    "        eps=float(config_model[\"Optimizer\"][\"eps\"]),\n",
    "        weight_decay=config_model[\"Optimizer\"][\"weight_decay\"],\n",
    "        amsgrad=config_model[\"Optimizer\"][\"amsgrad\"],\n",
    "        maximize=config_model[\"Optimizer\"][\"maximize\"],\n",
    "        foreach=config_model[\"Optimizer\"][\"foreach\"],\n",
    "        capturable=config_model[\"Optimizer\"][\"capturable\"],\n",
    "        differentiable=config_model[\"Optimizer\"][\"differentiable\"],\n",
    "        fused=config_model[\"Optimizer\"][\"fused\"],\n",
    "        scheduler=config_model[\"Scheduler\"][\"scheduler\"],\n",
    "        factor=config_model[\"Scheduler\"][\"factor\"],\n",
    "        patience=config_model[\"Scheduler\"][\"patience\"],\n",
    "        threshold=config_model[\"Scheduler\"][\"threshold\"],\n",
    "        threshold_mode=config_model[\"Scheduler\"][\"threshold_mode\"],\n",
    "        cooldown=config_model[\"Scheduler\"][\"cooldown\"],\n",
    "        min_lr=config_model[\"Scheduler\"][\"min_lr\"],\n",
    "        verbose=config_model[\"Scheduler\"][\"verbose\"],\n",
    "        loss=config_model[\"Loss\"][\"loss\"],\n",
    "        num_epochs=config_model[\"Training\"][\"num_epochs\"],\n",
    "        save_dir=config_model[\"Training\"][\"save_dir\"],\n",
    "        save_period=config_model[\"Training\"][\"save_period\"],\n",
    "        log_period=config_model[\"Training\"][\"log_period\"],\n",
    "        log_dir=config_model[\"Training\"][\"log_dir\"],\n",
    "        log_file=config_model[\"Training\"][\"log_file\"],\n",
    "        log_level=config_model[\"Training\"][\"log_level\"],\n",
    "        seed=config_model[\"Training\"][\"seed\"],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# initialize config\n",
    "config = wandb.config\n",
    "\n",
    "model = ResnetFFN(\n",
    "    config.device,\n",
    "    config.num_outputs,\n",
    "    config.batch_first,\n",
    "    config.conv_channel,\n",
    "    config.fc_hidden_dims,\n",
    ").to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIALIZE DATA LOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide train and test dataset into batches\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=config.shuffle,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=config.pin_memory,\n",
    "    drop_last=config.drop_last,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=config.shuffle,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=config.pin_memory,\n",
    "    drop_last=config.drop_last,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=config.shuffle,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=config.pin_memory,\n",
    "    drop_last=config.drop_last,\n",
    ")\n",
    "\n",
    "# Check whether data is splitted correctly -> X_.shape: (batch, seq, encoding), y_.shape: (batch)\n",
    "for i, (X_, y_) in enumerate(train_loader):\n",
    "    print(\"X.shape:\", X_.shape, \"   y.shape: \", y_.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze first layers of backbone\n",
    "for name, param in model.named_parameters():\n",
    "    if name == \"backbone.6.0.conv1.weight\":\n",
    "        break\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe initial performance of the model without any training\n",
    "model.eval()\n",
    "test(model, test_loader, device, config.project_name, save_model=False)\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.L1Loss()\n",
    "# criterion = nn.SmoothL1Loss()\n",
    "\n",
    "backbone_params = list(model.backbone.parameters())\n",
    "other_params = [\n",
    "    param for name, param in model.named_parameters() if \"backbone\" not in name\n",
    "]\n",
    "\n",
    "# Define different learning rates\n",
    "backbone_lr = config.backbone_lr\n",
    "other_lr = config.other_lr\n",
    "\n",
    "# Create parameter groups\n",
    "param_groups = [\n",
    "    {\"params\": backbone_params, \"lr\": backbone_lr},\n",
    "    {\"params\": other_params, \"lr\": other_lr},\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    param_groups,\n",
    "    betas=(config.beta1, config.beta2),\n",
    "    eps=config.eps,\n",
    "    weight_decay=config.weight_decay,\n",
    "    amsgrad=config.amsgrad,\n",
    "    maximize=config.maximize,\n",
    "    foreach=config.foreach,\n",
    "    capturable=config.capturable,\n",
    "    differentiable=config.differentiable,\n",
    "    fused=config.fused,\n",
    ")\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=config.gamma)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=config.factor,\n",
    "    patience=config.patience,\n",
    "    threshold=config.threshold,\n",
    "    threshold_mode=config.threshold_mode,\n",
    "    cooldown=config.cooldown,\n",
    "    min_lr=[config.min_lr, config.min_lr],\n",
    "    verbose=config.verbose,\n",
    ")\n",
    "\n",
    "print(\"optimizer: \", optimizer)\n",
    "print(\"\")\n",
    "print(\"loss function: \", criterion)\n",
    "print(\"\")\n",
    "print(\"scheduler\", scheduler)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train(model, train_loader, val_loader, criterion, optimizer, scheduler, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model -> no need to compute gradients (for memory efficiency)\n",
    "test(model, test_loader, device, config.project_name, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print learnable parameter values after training\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 1\n",
    "for name, layer in model.named_children():\n",
    "    if name == \"backbone\":\n",
    "        # print(\"LAYER \", iter, \": \", layer)\n",
    "        # iter += 1\n",
    "        for layer_num, layer in layer.named_children():\n",
    "            print(\"Layer Number\", layer_num, \":\", layer)\n",
    "        # print(\"Layer \", iter, \": \", layer)\n",
    "        # print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    # if name == \"backbone.6.0.conv1.weight\":\n",
    "    #     break\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = torch.load(\"pretrained/model_state_dict_mse_0_0045.pth\")\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "img = Image.open(\n",
    "    \"data/CodingChallenge_v2/imgs/4d8d3780-e786-400f-b2fd-62eed728ba8c.jpg\"\n",
    ")\n",
    "img_tensor = transform_norm(img).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(img_tensor)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "case_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

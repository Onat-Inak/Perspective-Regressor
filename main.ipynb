{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import yaml\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dataset import Dataset\n",
    "from tools.test import test\n",
    "from tools.train import train\n",
    "from check_cuda import check_cuda\n",
    "from models.ResnetFFN import ResnetFFN\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "csv_file_path = \"./data/CodingChallenge_v2/car_imgs_4000.csv\"\n",
    "images_dir = \"./data/CodingChallenge_v2/imgs\"\n",
    "\n",
    "# Initialize list to hold training data\n",
    "images = []\n",
    "scores_hood = []\n",
    "scores_backdoor_left = []\n",
    "\n",
    "IMG_H = 224\n",
    "IMG_W = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set predetermined mean and std values \n",
    "mean_images = np.array([122.09624237, 123.38567456, 120.75862292]) / 255.0\n",
    "std_images = np.array([61.13438223, 62.09970917, 65.60647365]) / 255.0\n",
    "\n",
    "# Resize images, convert to torch.Tensor and normalize the dataset regarding predetermined mean and std values\n",
    "transform_norm = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((IMG_H, IMG_W)),  # Resize images to (IMG_H x IMG_W)\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean_images, std_images)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Shape: (4000, 3, 224, 224)\n",
      "Scores Hood Shape: (4000, 1)\n",
      "Scores Backdoor Left Shape: (4000, 1)\n",
      "\n",
      "Mean of Image Pixels:  [-0.00146458 -0.00061618 -0.00030073]    ->   [values should be near 0!]\n",
      "Standard Deviation of Image Pixels:  [1.026527  1.024326  1.0237782]    ->   [values should be near 1!]\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "with open(csv_file_path, mode=\"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    \n",
    "    # Skip the header\n",
    "    next(csv_reader)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        filename, score_hood, score_backdoor_left = row\n",
    "        # print(f\"Filename: {filename}, Score Hood: {score_hood}, Score Backdoor Left: {score_backdoor_left}\")\n",
    "        image_path = os.path.join(images_dir, filename)\n",
    "\n",
    "        # Check if the image file exists\n",
    "        if os.path.exists(image_path):\n",
    "            \n",
    "            # Append image and perspective scores to the corresponding lists\n",
    "            with Image.open(image_path) as img:\n",
    "                images.append(np.array(transform_norm(img), dtype=np.float32))\n",
    "                \n",
    "            scores_hood.append(np.array(float(score_hood), dtype=np.float32))\n",
    "            scores_backdoor_left.append(np.array(float(score_backdoor_left), dtype=np.float32))\n",
    "\n",
    "# Check if some scores are NaN\n",
    "for i in range(len(images)):\n",
    "    if np.isnan(scores_hood[i]) or np.isnan(scores_backdoor_left[i]):\n",
    "        print(f\"Found NaN scores at index {i}\")\n",
    "        break\n",
    "    \n",
    "images = np.array(images) # Shape: (4000, 3, IMG_H, IMG_W)\n",
    "scores_hood = np.array(scores_hood).reshape(-1, 1) # Shape: (4000, 1)\n",
    "scores_backdoor_left = np.array(scores_backdoor_left).reshape(-1, 1) # Shape: (4000, 1)\n",
    "\n",
    "# Test size of variables\n",
    "print(f\"Images Shape: {images.shape}\")\n",
    "print(f\"Scores Hood Shape: {scores_hood.shape}\")\n",
    "print(f\"Scores Backdoor Left Shape: {scores_backdoor_left.shape}\")\n",
    "print(\"\")\n",
    "print(\"Mean of Image Pixels: \", np.mean(images, axis=(0,2,3)), \"   ->   [values should be near 0!]\")\n",
    "print(\"Standard Deviation of Image Pixels: \", np.std(images, axis=(0,2,3)), \"   ->   [values should be near 1!]\")\n",
    "# print(f\"Mean of images: {mean_images}\")\n",
    "# print(f\"Std of images: {std_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IMPORTANT: Our dataset includes a lot of white pixels, which is due to the fact\n",
      "            that the images are synthetically generated and have a lot of white backgrounds!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the pixel values\n",
    "plt.hist(images.ravel(), bins=50, density=True)\n",
    "plt.xlabel(\"pixel values\")\n",
    "plt.ylabel(\"relative frequency\")\n",
    "plt.title(\"distribution of pixels\")\n",
    "\n",
    "print(\"\"\"\\nIMPORTANT: Our dataset includes a lot of white pixels, which is due to the fact\n",
    "            that the images are synthetically generated and have a lot of white backgrounds!\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score hood: min=0.0, max=0.9224276542663574, mean=0.3030319809913635, std=0.3825345039367676, num_zeros=2103, mean_non_zero=0.6389709711074829\n",
      "Score backdoor left: min=0.0, max=0.9395412802696228, mean=0.3133678734302521, std=0.3722873628139496, num_zeros=2086, mean_non_zero=0.6548962593078613\n"
     ]
    }
   ],
   "source": [
    "# Analyze the perspective scores characteristics\n",
    "\n",
    "scores_hood = np.array(scores_hood)\n",
    "scores_backdoor_left = np.array(scores_backdoor_left)\n",
    "\n",
    "print(f\"Score hood: min={scores_hood.min()}, max={scores_hood.max()}, \\\n",
    "mean={scores_hood.mean()}, std={scores_hood.std()}, num_zeros={np.count_nonzero(scores_hood==0)}, \\\n",
    "mean_non_zero={np.mean(scores_hood[scores_hood!=0])}\")\n",
    "\n",
    "print(f\"Score backdoor left: min={scores_backdoor_left.min()}, \\\n",
    "max={scores_backdoor_left.max()}, mean={scores_backdoor_left.mean()}, \\\n",
    "std={scores_backdoor_left.std()}, num_zeros={np.count_nonzero(scores_backdoor_left==0)}, \\\n",
    "mean_non_zero={np.mean(scores_backdoor_left[scores_backdoor_left!=0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size: torch.Size([4000, 3, 224, 224]) X type: <class 'torch.Tensor'> X.dtype: torch.float32\n",
      "y size: torch.Size([4000, 2]) y type: <class 'torch.Tensor'> y.dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to tensors and prepare input data \n",
    "X = torch.from_numpy(images) # Size: ([4000, 506, 674, 3])\n",
    "\n",
    "# Concatenate the two scores into a single tensor as the model's output data\n",
    "y = torch.from_numpy(np.concatenate((scores_hood, scores_backdoor_left), axis=1)) # Size: [(4000, 2)]\n",
    "\n",
    "print(\"X size:\", X.size(), \"X type:\", type(X), \"X.dtype:\", X.dtype)\n",
    "print(\"y size:\", y.size(), \"y type:\", type(y), \"y.dtype:\", y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! \n",
      "Number of GPUs: 1\n",
      "Current CUDA device: 0 (NVIDIA GeForce RTX 2070 SUPER)\n",
      "Python version: 3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]\n",
      "\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# check cuda availability\n",
    "check_cuda()\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size:  torch.Size([3200, 3, 224, 224])\n",
      "X_test size:  torch.Size([400, 3, 224, 224])\n",
      "X_val size:  torch.Size([400, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Define train, test and validation ratios\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.1\n",
    "val_ratio = 0.1\n",
    "\n",
    "# Split the data / Shuffle it and maintain class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = (1 - train_ratio), random_state=42, shuffle=True)\n",
    "\n",
    "# Further split train_data into test and validation sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = test_ratio/(test_ratio + val_ratio), random_state=42, shuffle=True)\n",
    "\n",
    "print(\"X_train size: \", X_train.size())\n",
    "print(\"X_test size: \", X_test.size())\n",
    "print(\"X_val size: \", X_val.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Push torch.Tensors to CPU\n",
    "# X_train, y_train = X_train.to('cpu', dtype=torch.float32), y_train.to('cpu', dtype=torch.float32)\n",
    "# X_test, y_test = X_test.to('cpu', dtype=torch.float32), y_test.to('cpu', dtype=torch.float32)\n",
    "# X_val, y_val = X_val.to('cpu', dtype=torch.float32), y_val.to('cpu', dtype=torch.float32)\n",
    "\n",
    "# Create a custom dataset and push tensors to CPU\n",
    "train_dataset = Dataset(X_train, y_train, 'cpu')\n",
    "test_dataset = Dataset(X_test, y_test, 'cpu')\n",
    "val_dataset = Dataset(X_val, y_val, 'cpu')\n",
    "\n",
    "del X, y, X_train, y_train, X_test, y_test, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Allocated: 0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Show how much memory (VRAM) is allocated to GPU\n",
    "gpu_memory_allocated = torch.cuda.memory_allocated(device)\n",
    "\n",
    "# Convert memory from bytes to GB\n",
    "gpu_memory_allocated_gb = gpu_memory_allocated / 1024**3\n",
    "\n",
    "# Print the memory allocated to the GPU\n",
    "print(\"GPU Memory Allocated:\", gpu_memory_allocated_gb, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config\n",
    "\n",
    "with open(os.getenv(\"CONFIG_DIR\"), \"r\") as config_file:\n",
    "    config_model = yaml.safe_load(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN-FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monat-inak\u001b[0m (\u001b[33monat-inak-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/onatinak/workspace/Perspective-Regressor/wandb/run-20240810_144611-ekjs1vu4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/onat-inak-/Perspective-Regressor-Resnet-FFN/runs/ekjs1vu4' target=\"_blank\">proud-snowball-44</a></strong> to <a href='https://wandb.ai/onat-inak-/Perspective-Regressor-Resnet-FFN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/onat-inak-/Perspective-Regressor-Resnet-FFN' target=\"_blank\">https://wandb.ai/onat-inak-/Perspective-Regressor-Resnet-FFN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/onat-inak-/Perspective-Regressor-Resnet-FFN/runs/ekjs1vu4' target=\"_blank\">https://wandb.ai/onat-inak-/Perspective-Regressor-Resnet-FFN/runs/ekjs1vu4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResnetFFN(\n",
      "  (preprocess): ImageClassification(\n",
      "      crop_size=[224]\n",
      "      resize_size=[256]\n",
      "      mean=[0.485, 0.456, 0.406]\n",
      "      std=[0.229, 0.224, 0.225]\n",
      "      interpolation=InterpolationMode.BILINEAR\n",
      "  )\n",
      "  (backbone): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (conv1x1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize W&B for RNN-Classifier\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project = config_model[\"Project\"][\"project_name\"],\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config = dict(\n",
    "        device = device,\n",
    "        project_name = config_model[\"Project\"][\"project_name\"],\n",
    "        model_name = config_model[\"Model\"][\"model_name\"],\n",
    "        num_outputs = config_model[\"Model\"][\"num_outputs\"],\n",
    "        batch_first = config_model[\"Model\"][\"batch_first\"],\n",
    "        conv_channel = config_model[\"Model\"][\"conv_channel\"],\n",
    "        fc_hidden_dims = config_model[\"Model\"][\"fc_hidden_dims\"],\n",
    "        batch_size = config_model[\"Dataloader\"][\"batch_size\"],\n",
    "        shuffle = config_model[\"Dataloader\"][\"shuffle\"],\n",
    "        num_workers = config_model[\"Dataloader\"][\"num_workers\"],\n",
    "        pin_memory = config_model[\"Dataloader\"][\"pin_memory\"],\n",
    "        drop_last = config_model[\"Dataloader\"][\"drop_last\"],\n",
    "        optimizer = config_model[\"Optimizer\"][\"optimizer\"],\n",
    "        backbone_lr = float(config_model[\"Optimizer\"][\"backbone_lr\"]),\n",
    "        other_lr = float(config_model[\"Optimizer\"][\"other_lr\"]),\n",
    "        beta1 = config_model[\"Optimizer\"][\"beta1\"],\n",
    "        beta2 = config_model[\"Optimizer\"][\"beta2\"],\n",
    "        eps = float(config_model[\"Optimizer\"][\"eps\"]),\n",
    "        weight_decay = config_model[\"Optimizer\"][\"weight_decay\"],\n",
    "        amsgrad = config_model[\"Optimizer\"][\"amsgrad\"],\n",
    "        maximize = config_model[\"Optimizer\"][\"maximize\"],\n",
    "        foreach = config_model[\"Optimizer\"][\"foreach\"],\n",
    "        capturable = config_model[\"Optimizer\"][\"capturable\"],\n",
    "        differentiable = config_model[\"Optimizer\"][\"differentiable\"],\n",
    "        fused = config_model[\"Optimizer\"][\"fused\"],\n",
    "        scheduler = config_model[\"Scheduler\"][\"scheduler\"],\n",
    "        factor = config_model[\"Scheduler\"][\"factor\"],\n",
    "        patience = config_model[\"Scheduler\"][\"patience\"],\n",
    "        threshold = config_model[\"Scheduler\"][\"threshold\"],\n",
    "        threshold_mode = config_model[\"Scheduler\"][\"threshold_mode\"],\n",
    "        cooldown = config_model[\"Scheduler\"][\"cooldown\"],\n",
    "        min_lr = config_model[\"Scheduler\"][\"min_lr\"],\n",
    "        verbose = config_model[\"Scheduler\"][\"verbose\"],\n",
    "        loss = config_model[\"Loss\"][\"loss\"],\n",
    "        num_epochs = config_model[\"Training\"][\"num_epochs\"],\n",
    "        save_dir = config_model[\"Training\"][\"save_dir\"],\n",
    "        save_period = config_model[\"Training\"][\"save_period\"],\n",
    "        log_period = config_model[\"Training\"][\"log_period\"],\n",
    "        log_dir = config_model[\"Training\"][\"log_dir\"],\n",
    "        log_file = config_model[\"Training\"][\"log_file\"],\n",
    "        log_level = config_model[\"Training\"][\"log_level\"],\n",
    "        seed = config_model[\"Training\"][\"seed\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# initialize config\n",
    "config = wandb.config\n",
    "\n",
    "model = ResnetFFN(config.device,\n",
    "                  config.num_outputs,\n",
    "                  config.batch_first,\n",
    "                  config.conv_channel,\n",
    "                  config.fc_hidden_dims).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIALIZE DATA LOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: torch.Size([64, 3, 224, 224])    y.shape:  torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "# Divide train and test dataset into batches\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=config.batch_size, shuffle=config.shuffle,num_workers=config.num_workers,\n",
    "    pin_memory = config.pin_memory, drop_last=config.drop_last\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=config.batch_size, shuffle=config.shuffle,num_workers=config.num_workers,\n",
    "    pin_memory = config.pin_memory, drop_last=config.drop_last\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=config.batch_size, shuffle=config.shuffle,num_workers=config.num_workers,\n",
    "    pin_memory = config.pin_memory, drop_last=config.drop_last\n",
    ")\n",
    "\n",
    "# Check whether data is splitted correctly -> X_.shape: (batch, seq, encoding), y_.shape: (batch)\n",
    "for i, (X_, y_) in enumerate(train_loader):\n",
    "    print(\"X.shape:\", X_.shape, \"   y.shape: \", y_.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze first layers of backbone\n",
    "for name, param in model.named_parameters():\n",
    "    if name == \"backbone.6.0.conv1.weight\":\n",
    "        break\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.40210795402526855\n",
      "Mean Squared Error (MSE): 0.18367990851402283\n",
      "total_y_[:20] [[0.3700371  0.45471597]\n",
      " [0.         0.90360767]\n",
      " [0.900389   0.        ]\n",
      " [0.         0.90242064]\n",
      " [0.         0.        ]\n",
      " [0.90399307 0.55720466]\n",
      " [0.4324251  0.        ]\n",
      " [0.         0.6101952 ]\n",
      " [0.90141463 0.5870535 ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.90502816 0.        ]\n",
      " [0.90308136 0.        ]\n",
      " [0.         0.91171664]\n",
      " [0.         0.740009  ]\n",
      " [0.9053432  0.21912862]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.42442623 0.32133132]\n",
      " [0.8347134  0.50849915]]\n",
      "total_outputs[:20] [[0.5013129  0.51612115]\n",
      " [0.5082096  0.5168248 ]\n",
      " [0.49385074 0.5172166 ]\n",
      " [0.50325596 0.5176824 ]\n",
      " [0.49885985 0.5137679 ]\n",
      " [0.5053423  0.51550025]\n",
      " [0.50465345 0.5174604 ]\n",
      " [0.49881965 0.51883507]\n",
      " [0.49388123 0.5130906 ]\n",
      " [0.5011418  0.51457804]\n",
      " [0.4945494  0.5166583 ]\n",
      " [0.5035416  0.5144926 ]\n",
      " [0.49909517 0.5135063 ]\n",
      " [0.49537575 0.51560706]\n",
      " [0.50690603 0.51200384]\n",
      " [0.4962837  0.51488316]\n",
      " [0.49647602 0.51382005]\n",
      " [0.50374144 0.5148754 ]\n",
      " [0.49768522 0.5158329 ]\n",
      " [0.49851716 0.51351196]]\n"
     ]
    }
   ],
   "source": [
    "# Observe initial performance of the model without any training\n",
    "model.eval()\n",
    "test(model, test_loader, device, config.project_name, save_model=False)\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer:  AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: False\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: False\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      ")\n",
      "\n",
      "loss function:  MSELoss()\n",
      "\n",
      "scheduler <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f3773d58f10>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onatinak/anaconda3/envs/perspective_regressor/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.L1Loss()\n",
    "# criterion = nn.SmoothL1Loss()\n",
    "\n",
    "backbone_params = list(model.backbone.parameters())\n",
    "other_params = [param for name, param in model.named_parameters() if \"backbone\" not in name]\n",
    "\n",
    "# Define different learning rates\n",
    "backbone_lr = config.backbone_lr\n",
    "other_lr = config.other_lr\n",
    "\n",
    "# Create parameter groups\n",
    "param_groups = [\n",
    "    {'params': backbone_params, 'lr': backbone_lr},\n",
    "    {'params': other_params, 'lr': other_lr}\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    param_groups,\n",
    "    betas=(config.beta1, config.beta2),\n",
    "    eps=config.eps,\n",
    "    weight_decay=config.weight_decay,\n",
    "    amsgrad=config.amsgrad,\n",
    "    maximize=config.maximize,\n",
    "    foreach=config.foreach,\n",
    "    capturable=config.capturable,\n",
    "    differentiable=config.differentiable,\n",
    "    fused=config.fused,\n",
    ")\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=config.gamma)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                       factor=config.factor, patience=config.patience,\n",
    "                                                       threshold=config.threshold, threshold_mode=config.threshold_mode,\n",
    "                                                       cooldown=config.cooldown, min_lr=[config.min_lr, config.min_lr],\n",
    "                                                       verbose=config.verbose)\n",
    "\n",
    "print(\"optimizer: \", optimizer)\n",
    "print(\"\")\n",
    "print(\"loss function: \", criterion)\n",
    "print(\"\")\n",
    "print(\"scheduler\", scheduler)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0a900c0f554157ba9fea8f05f08bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [10/50], Current Batch [10/1500], Train Loss: 0.1170\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [1/30], Step [20/50], Current Batch [20/1500], Train Loss: 0.0544\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [1/30], Step [30/50], Current Batch [30/1500], Train Loss: 0.0493\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [1/30], Step [40/50], Current Batch [40/1500], Train Loss: 0.0321\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [1/30], Step [50/50], Current Batch [50/1500], Train Loss: 0.0311\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Validation Loss: 0.04655 \n",
      "\n",
      "Epoch [2/30], Step [10/50], Current Batch [60/1500], Train Loss: 0.0228\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [2/30], Step [20/50], Current Batch [70/1500], Train Loss: 0.0204\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [2/30], Step [30/50], Current Batch [80/1500], Train Loss: 0.0305\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [2/30], Step [40/50], Current Batch [90/1500], Train Loss: 0.0240\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [2/30], Step [50/50], Current Batch [100/1500], Train Loss: 0.0214\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Validation Loss: 0.04106 \n",
      "\n",
      "Epoch [3/30], Step [10/50], Current Batch [110/1500], Train Loss: 0.0170\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [3/30], Step [20/50], Current Batch [120/1500], Train Loss: 0.0170\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [3/30], Step [30/50], Current Batch [130/1500], Train Loss: 0.0161\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [3/30], Step [40/50], Current Batch [140/1500], Train Loss: 0.0112\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [3/30], Step [50/50], Current Batch [150/1500], Train Loss: 0.0159\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Validation Loss: 0.01924 \n",
      "\n",
      "Epoch [4/30], Step [10/50], Current Batch [160/1500], Train Loss: 0.0114\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [4/30], Step [20/50], Current Batch [170/1500], Train Loss: 0.0120\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [4/30], Step [30/50], Current Batch [180/1500], Train Loss: 0.0122\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [4/30], Step [40/50], Current Batch [190/1500], Train Loss: 0.0121\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [4/30], Step [50/50], Current Batch [200/1500], Train Loss: 0.0121\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Validation Loss: 0.02040 \n",
      "\n",
      "Epoch [5/30], Step [10/50], Current Batch [210/1500], Train Loss: 0.0084\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [5/30], Step [20/50], Current Batch [220/1500], Train Loss: 0.0099\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [5/30], Step [30/50], Current Batch [230/1500], Train Loss: 0.0094\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [5/30], Step [40/50], Current Batch [240/1500], Train Loss: 0.0093\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [5/30], Step [50/50], Current Batch [250/1500], Train Loss: 0.0073\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Validation Loss: 0.01605 \n",
      "\n",
      "Epoch [6/30], Step [10/50], Current Batch [260/1500], Train Loss: 0.0064\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [6/30], Step [20/50], Current Batch [270/1500], Train Loss: 0.0069\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [6/30], Step [30/50], Current Batch [280/1500], Train Loss: 0.0066\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [6/30], Step [40/50], Current Batch [290/1500], Train Loss: 0.0052\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [6/30], Step [50/50], Current Batch [300/1500], Train Loss: 0.0073\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Validation Loss: 0.01679 \n",
      "\n",
      "Epoch [7/30], Step [10/50], Current Batch [310/1500], Train Loss: 0.0050\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [7/30], Step [20/50], Current Batch [320/1500], Train Loss: 0.0046\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [7/30], Step [30/50], Current Batch [330/1500], Train Loss: 0.0070\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [7/30], Step [40/50], Current Batch [340/1500], Train Loss: 0.0053\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [7/30], Step [50/50], Current Batch [350/1500], Train Loss: 0.0046\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Validation Loss: 0.01323 \n",
      "\n",
      "Epoch [8/30], Step [10/50], Current Batch [360/1500], Train Loss: 0.0058\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [8/30], Step [20/50], Current Batch [370/1500], Train Loss: 0.0038\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [8/30], Step [30/50], Current Batch [380/1500], Train Loss: 0.0044\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [8/30], Step [40/50], Current Batch [390/1500], Train Loss: 0.0035\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [8/30], Step [50/50], Current Batch [400/1500], Train Loss: 0.0040\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Validation Loss: 0.01159 \n",
      "\n",
      "Epoch [9/30], Step [10/50], Current Batch [410/1500], Train Loss: 0.0027\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [9/30], Step [20/50], Current Batch [420/1500], Train Loss: 0.0031\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [9/30], Step [30/50], Current Batch [430/1500], Train Loss: 0.0031\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [9/30], Step [40/50], Current Batch [440/1500], Train Loss: 0.0028\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [9/30], Step [50/50], Current Batch [450/1500], Train Loss: 0.0033\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Validation Loss: 0.01179 \n",
      "\n",
      "Epoch [10/30], Step [10/50], Current Batch [460/1500], Train Loss: 0.0026\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [10/30], Step [20/50], Current Batch [470/1500], Train Loss: 0.0031\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [10/30], Step [30/50], Current Batch [480/1500], Train Loss: 0.0025\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [10/30], Step [40/50], Current Batch [490/1500], Train Loss: 0.0037\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [10/30], Step [50/50], Current Batch [500/1500], Train Loss: 0.0032\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Validation Loss: 0.01255 \n",
      "\n",
      "Epoch [11/30], Step [10/50], Current Batch [510/1500], Train Loss: 0.0030\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [11/30], Step [20/50], Current Batch [520/1500], Train Loss: 0.0031\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [11/30], Step [30/50], Current Batch [530/1500], Train Loss: 0.0031\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [11/30], Step [40/50], Current Batch [540/1500], Train Loss: 0.0031\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [11/30], Step [50/50], Current Batch [550/1500], Train Loss: 0.0028\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Validation Loss: 0.01655 \n",
      "\n",
      "Epoch [12/30], Step [10/50], Current Batch [560/1500], Train Loss: 0.0033\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [12/30], Step [20/50], Current Batch [570/1500], Train Loss: 0.0033\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [12/30], Step [30/50], Current Batch [580/1500], Train Loss: 0.0048\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [12/30], Step [40/50], Current Batch [590/1500], Train Loss: 0.0037\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [12/30], Step [50/50], Current Batch [600/1500], Train Loss: 0.0035\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Validation Loss: 0.01257 \n",
      "\n",
      "Epoch [13/30], Step [10/50], Current Batch [610/1500], Train Loss: 0.0032\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [13/30], Step [20/50], Current Batch [620/1500], Train Loss: 0.0028\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [13/30], Step [30/50], Current Batch [630/1500], Train Loss: 0.0034\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [13/30], Step [40/50], Current Batch [640/1500], Train Loss: 0.0028\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Epoch [13/30], Step [50/50], Current Batch [650/1500], Train Loss: 0.0032\n",
      "backbone_lr:  0.001 other_lr:  0.001\n",
      "Validation Loss: 0.01290 \n",
      "\n",
      "Epoch [14/30], Step [10/50], Current Batch [660/1500], Train Loss: 0.0027\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [14/30], Step [20/50], Current Batch [670/1500], Train Loss: 0.0023\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [14/30], Step [30/50], Current Batch [680/1500], Train Loss: 0.0016\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [14/30], Step [40/50], Current Batch [690/1500], Train Loss: 0.0024\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [14/30], Step [50/50], Current Batch [700/1500], Train Loss: 0.0021\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.01149 \n",
      "\n",
      "Epoch [15/30], Step [10/50], Current Batch [710/1500], Train Loss: 0.0015\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [15/30], Step [20/50], Current Batch [720/1500], Train Loss: 0.0020\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [15/30], Step [30/50], Current Batch [730/1500], Train Loss: 0.0017\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [15/30], Step [40/50], Current Batch [740/1500], Train Loss: 0.0019\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [15/30], Step [50/50], Current Batch [750/1500], Train Loss: 0.0017\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.01094 \n",
      "\n",
      "Epoch [16/30], Step [10/50], Current Batch [760/1500], Train Loss: 0.0024\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [16/30], Step [20/50], Current Batch [770/1500], Train Loss: 0.0014\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [16/30], Step [30/50], Current Batch [780/1500], Train Loss: 0.0009\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [16/30], Step [40/50], Current Batch [790/1500], Train Loss: 0.0011\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [16/30], Step [50/50], Current Batch [800/1500], Train Loss: 0.0015\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.01089 \n",
      "\n",
      "Epoch [17/30], Step [10/50], Current Batch [810/1500], Train Loss: 0.0009\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [17/30], Step [20/50], Current Batch [820/1500], Train Loss: 0.0011\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [17/30], Step [30/50], Current Batch [830/1500], Train Loss: 0.0011\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [17/30], Step [40/50], Current Batch [840/1500], Train Loss: 0.0010\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [17/30], Step [50/50], Current Batch [850/1500], Train Loss: 0.0014\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.01041 \n",
      "\n",
      "Epoch [18/30], Step [10/50], Current Batch [860/1500], Train Loss: 0.0012\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [18/30], Step [20/50], Current Batch [870/1500], Train Loss: 0.0013\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [18/30], Step [30/50], Current Batch [880/1500], Train Loss: 0.0009\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [18/30], Step [40/50], Current Batch [890/1500], Train Loss: 0.0011\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [18/30], Step [50/50], Current Batch [900/1500], Train Loss: 0.0010\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.00988 \n",
      "\n",
      "Epoch [19/30], Step [10/50], Current Batch [910/1500], Train Loss: 0.0009\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [19/30], Step [20/50], Current Batch [920/1500], Train Loss: 0.0009\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [19/30], Step [30/50], Current Batch [930/1500], Train Loss: 0.0009\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [19/30], Step [40/50], Current Batch [940/1500], Train Loss: 0.0013\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [19/30], Step [50/50], Current Batch [950/1500], Train Loss: 0.0010\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.01123 \n",
      "\n",
      "Epoch [20/30], Step [10/50], Current Batch [960/1500], Train Loss: 0.0010\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [20/30], Step [20/50], Current Batch [970/1500], Train Loss: 0.0010\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [20/30], Step [30/50], Current Batch [980/1500], Train Loss: 0.0011\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [20/30], Step [40/50], Current Batch [990/1500], Train Loss: 0.0007\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [20/30], Step [50/50], Current Batch [1000/1500], Train Loss: 0.0010\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.00990 \n",
      "\n",
      "Epoch [21/30], Step [10/50], Current Batch [1010/1500], Train Loss: 0.0007\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [21/30], Step [20/50], Current Batch [1020/1500], Train Loss: 0.0009\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [21/30], Step [30/50], Current Batch [1030/1500], Train Loss: 0.0008\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [21/30], Step [40/50], Current Batch [1040/1500], Train Loss: 0.0008\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [21/30], Step [50/50], Current Batch [1050/1500], Train Loss: 0.0008\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.00979 \n",
      "\n",
      "Epoch [22/30], Step [10/50], Current Batch [1060/1500], Train Loss: 0.0008\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [22/30], Step [20/50], Current Batch [1070/1500], Train Loss: 0.0009\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [22/30], Step [30/50], Current Batch [1080/1500], Train Loss: 0.0007\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [22/30], Step [40/50], Current Batch [1090/1500], Train Loss: 0.0009\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [22/30], Step [50/50], Current Batch [1100/1500], Train Loss: 0.0007\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.01010 \n",
      "\n",
      "Epoch [23/30], Step [10/50], Current Batch [1110/1500], Train Loss: 0.0006\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [23/30], Step [20/50], Current Batch [1120/1500], Train Loss: 0.0008\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [23/30], Step [30/50], Current Batch [1130/1500], Train Loss: 0.0006\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [23/30], Step [40/50], Current Batch [1140/1500], Train Loss: 0.0008\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [23/30], Step [50/50], Current Batch [1150/1500], Train Loss: 0.0010\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.00956 \n",
      "\n",
      "Epoch [24/30], Step [10/50], Current Batch [1160/1500], Train Loss: 0.0008\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [24/30], Step [20/50], Current Batch [1170/1500], Train Loss: 0.0010\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [24/30], Step [30/50], Current Batch [1180/1500], Train Loss: 0.0008\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [24/30], Step [40/50], Current Batch [1190/1500], Train Loss: 0.0006\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [24/30], Step [50/50], Current Batch [1200/1500], Train Loss: 0.0006\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.00891 \n",
      "\n",
      "Epoch [25/30], Step [10/50], Current Batch [1210/1500], Train Loss: 0.0007\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [25/30], Step [20/50], Current Batch [1220/1500], Train Loss: 0.0007\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [25/30], Step [30/50], Current Batch [1230/1500], Train Loss: 0.0008\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [25/30], Step [40/50], Current Batch [1240/1500], Train Loss: 0.0006\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [25/30], Step [50/50], Current Batch [1250/1500], Train Loss: 0.0011\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.00949 \n",
      "\n",
      "Epoch [26/30], Step [10/50], Current Batch [1260/1500], Train Loss: 0.0009\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [26/30], Step [20/50], Current Batch [1270/1500], Train Loss: 0.0009\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [26/30], Step [30/50], Current Batch [1280/1500], Train Loss: 0.0008\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [26/30], Step [40/50], Current Batch [1290/1500], Train Loss: 0.0006\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [26/30], Step [50/50], Current Batch [1300/1500], Train Loss: 0.0006\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.00997 \n",
      "\n",
      "Epoch [27/30], Step [10/50], Current Batch [1310/1500], Train Loss: 0.0006\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [27/30], Step [20/50], Current Batch [1320/1500], Train Loss: 0.0007\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [27/30], Step [30/50], Current Batch [1330/1500], Train Loss: 0.0007\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [27/30], Step [40/50], Current Batch [1340/1500], Train Loss: 0.0008\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [27/30], Step [50/50], Current Batch [1350/1500], Train Loss: 0.0009\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.00888 \n",
      "\n",
      "Epoch [28/30], Step [10/50], Current Batch [1360/1500], Train Loss: 0.0008\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [28/30], Step [20/50], Current Batch [1370/1500], Train Loss: 0.0005\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [28/30], Step [30/50], Current Batch [1380/1500], Train Loss: 0.0006\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [28/30], Step [40/50], Current Batch [1390/1500], Train Loss: 0.0008\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [28/30], Step [50/50], Current Batch [1400/1500], Train Loss: 0.0007\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.00955 \n",
      "\n",
      "Epoch [29/30], Step [10/50], Current Batch [1410/1500], Train Loss: 0.0006\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [29/30], Step [20/50], Current Batch [1420/1500], Train Loss: 0.0006\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [29/30], Step [30/50], Current Batch [1430/1500], Train Loss: 0.0007\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [29/30], Step [40/50], Current Batch [1440/1500], Train Loss: 0.0007\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [29/30], Step [50/50], Current Batch [1450/1500], Train Loss: 0.0007\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.01000 \n",
      "\n",
      "Epoch [30/30], Step [10/50], Current Batch [1460/1500], Train Loss: 0.0007\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [30/30], Step [20/50], Current Batch [1470/1500], Train Loss: 0.0005\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [30/30], Step [30/50], Current Batch [1480/1500], Train Loss: 0.0007\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [30/30], Step [40/50], Current Batch [1490/1500], Train Loss: 0.0007\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Epoch [30/30], Step [50/50], Current Batch [1500/1500], Train Loss: 0.0004\n",
      "backbone_lr:  0.0002 other_lr:  0.0002\n",
      "Validation Loss: 0.00908 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train(model, train_loader, val_loader, criterion, optimizer, scheduler, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.046111688017845154\n",
      "Mean Squared Error (MSE): 0.01003006100654602\n",
      "total_y_[:20] [[0.         0.29002804]\n",
      " [0.         0.91863   ]\n",
      " [0.25191772 0.23564024]\n",
      " [0.8847584  0.        ]\n",
      " [0.27683762 0.        ]\n",
      " [0.9061739  0.        ]\n",
      " [0.         0.9083111 ]\n",
      " [0.5065203  0.        ]\n",
      " [0.9044935  0.        ]\n",
      " [0.8755963  0.        ]\n",
      " [0.53714025 0.        ]\n",
      " [0.         0.15921834]\n",
      " [0.06197416 0.        ]\n",
      " [0.45201138 0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.9063536 ]\n",
      " [0.         0.90115684]\n",
      " [0.         0.        ]\n",
      " [0.90036    0.        ]\n",
      " [0.         0.        ]]\n",
      "total_outputs[:20] [[3.6669868e-01 5.3119253e-02]\n",
      " [2.4954220e-02 9.8144537e-01]\n",
      " [3.7287733e-01 1.6800380e-01]\n",
      " [6.7883575e-01 3.7766329e-04]\n",
      " [2.1632075e-01 1.5872028e-02]\n",
      " [9.2359275e-01 1.5857499e-03]\n",
      " [2.3765413e-02 7.8826475e-01]\n",
      " [5.7462329e-01 1.2479388e-02]\n",
      " [8.8810039e-01 2.6959931e-03]\n",
      " [8.9663625e-01 1.8837911e-03]\n",
      " [3.6065936e-01 7.2320938e-02]\n",
      " [1.1407895e-03 1.0486152e-02]\n",
      " [5.1310759e-02 9.6638892e-03]\n",
      " [5.2479589e-01 6.5837931e-03]\n",
      " [3.1272968e-04 4.6643079e-03]\n",
      " [3.9242883e-03 8.7684226e-01]\n",
      " [3.3708692e-03 8.4377706e-01]\n",
      " [1.5062217e-03 9.6350886e-02]\n",
      " [8.8055784e-01 9.7828545e-03]\n",
      " [8.7452475e-03 1.2011803e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Test the model -> no need to compute gradients (for memory efficiency)\n",
    "test(model, test_loader, device, config.project_name, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print learnable parameter values after training\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c5382f74bd4758a6b0d1c506d2c219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='9.486 MB of 94.649 MB uploaded\\r'), FloatProgress(value=0.10022762878153255, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MAE</td><td>█▁</td></tr><tr><td>MSE</td><td>█▁</td></tr><tr><td>backbone_lr</td><td>█████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>current_batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>other_lr</td><td>█████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MAE</td><td>0.04611</td></tr><tr><td>MSE</td><td>0.01003</td></tr><tr><td>backbone_lr</td><td>0.0002</td></tr><tr><td>current_batch</td><td>1500</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>other_lr</td><td>0.0002</td></tr><tr><td>train_loss</td><td>0.00043</td></tr><tr><td>val_loss</td><td>0.00908</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">proud-snowball-44</strong> at: <a href='https://wandb.ai/onat-inak-/Perspective-Regressor-Resnet-FFN/runs/ekjs1vu4' target=\"_blank\">https://wandb.ai/onat-inak-/Perspective-Regressor-Resnet-FFN/runs/ekjs1vu4</a><br/> View project at: <a href='https://wandb.ai/onat-inak-/Perspective-Regressor-Resnet-FFN' target=\"_blank\">https://wandb.ai/onat-inak-/Perspective-Regressor-Resnet-FFN</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240810_144611-ekjs1vu4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Number 0 : Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "Layer Number 1 : BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Layer Number 2 : ReLU(inplace=True)\n",
      "Layer Number 3 : MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "Layer Number 4 : Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer Number 5 : Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer Number 6 : Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer Number 7 : Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer Number 8 : AdaptiveAvgPool2d(output_size=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "iter = 1\n",
    "for name, layer in model.named_children():\n",
    "    if name == \"backbone\":\n",
    "        # print(\"LAYER \", iter, \": \", layer)\n",
    "        # iter += 1\n",
    "        for layer_num, layer in layer.named_children():\n",
    "            print(\"Layer Number\", layer_num, \":\", layer)\n",
    "        # print(\"Layer \", iter, \": \", layer)\n",
    "        # print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.0.weight\n",
      "backbone.1.weight\n",
      "backbone.1.bias\n",
      "backbone.4.0.conv1.weight\n",
      "backbone.4.0.bn1.weight\n",
      "backbone.4.0.bn1.bias\n",
      "backbone.4.0.conv2.weight\n",
      "backbone.4.0.bn2.weight\n",
      "backbone.4.0.bn2.bias\n",
      "backbone.4.0.conv3.weight\n",
      "backbone.4.0.bn3.weight\n",
      "backbone.4.0.bn3.bias\n",
      "backbone.4.0.downsample.0.weight\n",
      "backbone.4.0.downsample.1.weight\n",
      "backbone.4.0.downsample.1.bias\n",
      "backbone.4.1.conv1.weight\n",
      "backbone.4.1.bn1.weight\n",
      "backbone.4.1.bn1.bias\n",
      "backbone.4.1.conv2.weight\n",
      "backbone.4.1.bn2.weight\n",
      "backbone.4.1.bn2.bias\n",
      "backbone.4.1.conv3.weight\n",
      "backbone.4.1.bn3.weight\n",
      "backbone.4.1.bn3.bias\n",
      "backbone.4.2.conv1.weight\n",
      "backbone.4.2.bn1.weight\n",
      "backbone.4.2.bn1.bias\n",
      "backbone.4.2.conv2.weight\n",
      "backbone.4.2.bn2.weight\n",
      "backbone.4.2.bn2.bias\n",
      "backbone.4.2.conv3.weight\n",
      "backbone.4.2.bn3.weight\n",
      "backbone.4.2.bn3.bias\n",
      "backbone.5.0.conv1.weight\n",
      "backbone.5.0.bn1.weight\n",
      "backbone.5.0.bn1.bias\n",
      "backbone.5.0.conv2.weight\n",
      "backbone.5.0.bn2.weight\n",
      "backbone.5.0.bn2.bias\n",
      "backbone.5.0.conv3.weight\n",
      "backbone.5.0.bn3.weight\n",
      "backbone.5.0.bn3.bias\n",
      "backbone.5.0.downsample.0.weight\n",
      "backbone.5.0.downsample.1.weight\n",
      "backbone.5.0.downsample.1.bias\n",
      "backbone.5.1.conv1.weight\n",
      "backbone.5.1.bn1.weight\n",
      "backbone.5.1.bn1.bias\n",
      "backbone.5.1.conv2.weight\n",
      "backbone.5.1.bn2.weight\n",
      "backbone.5.1.bn2.bias\n",
      "backbone.5.1.conv3.weight\n",
      "backbone.5.1.bn3.weight\n",
      "backbone.5.1.bn3.bias\n",
      "backbone.5.2.conv1.weight\n",
      "backbone.5.2.bn1.weight\n",
      "backbone.5.2.bn1.bias\n",
      "backbone.5.2.conv2.weight\n",
      "backbone.5.2.bn2.weight\n",
      "backbone.5.2.bn2.bias\n",
      "backbone.5.2.conv3.weight\n",
      "backbone.5.2.bn3.weight\n",
      "backbone.5.2.bn3.bias\n",
      "backbone.5.3.conv1.weight\n",
      "backbone.5.3.bn1.weight\n",
      "backbone.5.3.bn1.bias\n",
      "backbone.5.3.conv2.weight\n",
      "backbone.5.3.bn2.weight\n",
      "backbone.5.3.bn2.bias\n",
      "backbone.5.3.conv3.weight\n",
      "backbone.5.3.bn3.weight\n",
      "backbone.5.3.bn3.bias\n",
      "backbone.6.0.conv1.weight\n",
      "backbone.6.0.bn1.weight\n",
      "backbone.6.0.bn1.bias\n",
      "backbone.6.0.conv2.weight\n",
      "backbone.6.0.bn2.weight\n",
      "backbone.6.0.bn2.bias\n",
      "backbone.6.0.conv3.weight\n",
      "backbone.6.0.bn3.weight\n",
      "backbone.6.0.bn3.bias\n",
      "backbone.6.0.downsample.0.weight\n",
      "backbone.6.0.downsample.1.weight\n",
      "backbone.6.0.downsample.1.bias\n",
      "backbone.6.1.conv1.weight\n",
      "backbone.6.1.bn1.weight\n",
      "backbone.6.1.bn1.bias\n",
      "backbone.6.1.conv2.weight\n",
      "backbone.6.1.bn2.weight\n",
      "backbone.6.1.bn2.bias\n",
      "backbone.6.1.conv3.weight\n",
      "backbone.6.1.bn3.weight\n",
      "backbone.6.1.bn3.bias\n",
      "backbone.6.2.conv1.weight\n",
      "backbone.6.2.bn1.weight\n",
      "backbone.6.2.bn1.bias\n",
      "backbone.6.2.conv2.weight\n",
      "backbone.6.2.bn2.weight\n",
      "backbone.6.2.bn2.bias\n",
      "backbone.6.2.conv3.weight\n",
      "backbone.6.2.bn3.weight\n",
      "backbone.6.2.bn3.bias\n",
      "backbone.6.3.conv1.weight\n",
      "backbone.6.3.bn1.weight\n",
      "backbone.6.3.bn1.bias\n",
      "backbone.6.3.conv2.weight\n",
      "backbone.6.3.bn2.weight\n",
      "backbone.6.3.bn2.bias\n",
      "backbone.6.3.conv3.weight\n",
      "backbone.6.3.bn3.weight\n",
      "backbone.6.3.bn3.bias\n",
      "backbone.6.4.conv1.weight\n",
      "backbone.6.4.bn1.weight\n",
      "backbone.6.4.bn1.bias\n",
      "backbone.6.4.conv2.weight\n",
      "backbone.6.4.bn2.weight\n",
      "backbone.6.4.bn2.bias\n",
      "backbone.6.4.conv3.weight\n",
      "backbone.6.4.bn3.weight\n",
      "backbone.6.4.bn3.bias\n",
      "backbone.6.5.conv1.weight\n",
      "backbone.6.5.bn1.weight\n",
      "backbone.6.5.bn1.bias\n",
      "backbone.6.5.conv2.weight\n",
      "backbone.6.5.bn2.weight\n",
      "backbone.6.5.bn2.bias\n",
      "backbone.6.5.conv3.weight\n",
      "backbone.6.5.bn3.weight\n",
      "backbone.6.5.bn3.bias\n",
      "backbone.7.0.conv1.weight\n",
      "backbone.7.0.bn1.weight\n",
      "backbone.7.0.bn1.bias\n",
      "backbone.7.0.conv2.weight\n",
      "backbone.7.0.bn2.weight\n",
      "backbone.7.0.bn2.bias\n",
      "backbone.7.0.conv3.weight\n",
      "backbone.7.0.bn3.weight\n",
      "backbone.7.0.bn3.bias\n",
      "backbone.7.0.downsample.0.weight\n",
      "backbone.7.0.downsample.1.weight\n",
      "backbone.7.0.downsample.1.bias\n",
      "backbone.7.1.conv1.weight\n",
      "backbone.7.1.bn1.weight\n",
      "backbone.7.1.bn1.bias\n",
      "backbone.7.1.conv2.weight\n",
      "backbone.7.1.bn2.weight\n",
      "backbone.7.1.bn2.bias\n",
      "backbone.7.1.conv3.weight\n",
      "backbone.7.1.bn3.weight\n",
      "backbone.7.1.bn3.bias\n",
      "backbone.7.2.conv1.weight\n",
      "backbone.7.2.bn1.weight\n",
      "backbone.7.2.bn1.bias\n",
      "backbone.7.2.conv2.weight\n",
      "backbone.7.2.bn2.weight\n",
      "backbone.7.2.bn2.bias\n",
      "backbone.7.2.conv3.weight\n",
      "backbone.7.2.bn3.weight\n",
      "backbone.7.2.bn3.bias\n",
      "conv1x1.weight\n",
      "conv1x1.bias\n",
      "fc.0.weight\n",
      "fc.0.bias\n",
      "fc.2.weight\n",
      "fc.2.bias\n",
      "fc.4.weight\n",
      "fc.4.bias\n",
      "fc.6.weight\n",
      "fc.6.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    # if name == \"backbone.6.0.conv1.weight\":\n",
    "    #     break\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_80376/328822835.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(\"pretrained/model_state_dict_mse_0_0045.pth\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1577, 0.9089]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"pretrained/model_state_dict_mse_0_0045.pth\")\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "img = Image.open(\"data/CodingChallenge_v2/imgs/4d8d3780-e786-400f-b2fd-62eed728ba8c.jpg\")\n",
    "img_tensor = transform_norm(img).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(img_tensor)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "case_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
